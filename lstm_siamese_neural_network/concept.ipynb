{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentences1</th>\n",
       "      <th>sentences2</th>\n",
       "      <th>is_similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         sentences1  \\\n",
       "0      0  What is the step by step guide to invest in sh...   \n",
       "1      1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2      2  How can I increase the speed of my internet co...   \n",
       "3      3  Why am I mentally very lonely? How can I solve...   \n",
       "4      4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                          sentences2  is_similar  \n",
       "0  What is the step by step guide to invest in sh...           0  \n",
       "1  What would happen if the Indian government sto...           0  \n",
       "2  How can Internet speed be increased by hacking...           0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...           0  \n",
       "4            Which fish would survive in salt water?           0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('sample_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentences1</th>\n",
       "      <th>sentences2</th>\n",
       "      <th>is_similar</th>\n",
       "      <th>clean_sentence1</th>\n",
       "      <th>clean_sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         sentences1  \\\n",
       "0      0  What is the step by step guide to invest in sh...   \n",
       "1      1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2      2  How can I increase the speed of my internet co...   \n",
       "3      3  Why am I mentally very lonely? How can I solve...   \n",
       "4      4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                          sentences2  is_similar  \\\n",
       "0  What is the step by step guide to invest in sh...           0   \n",
       "1  What would happen if the Indian government sto...           0   \n",
       "2  How can Internet speed be increased by hacking...           0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...           0   \n",
       "4            Which fish would survive in salt water?           0   \n",
       "\n",
       "                                     clean_sentence1  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "1     what is the story of kohinoor kohinoor diamond   \n",
       "2  how can i increase the speed of my internet co...   \n",
       "3   why am i mentally very lonely how can i solve it   \n",
       "4  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                     clean_sentence2  \n",
       "0  what is the step by step guide to invest in sh...  \n",
       "1  what would happen if the indian government sto...  \n",
       "2  how can internet speed be increased by hacking...  \n",
       "3  find the remainder when math2324math is divide...  \n",
       "4             which fish would survive in salt water  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean sentences: remove punctuation and convert to lowercase\n",
    "def clean_sentence(sentence):\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)  # Remove punctuation\n",
    "    sentence = sentence.lower()  # Convert to lowercase\n",
    "    return sentence\n",
    "\n",
    "# Apply the function to both columns and create new columns\n",
    "df['clean_sentence1'] = df['sentences1'].apply(clean_sentence)\n",
    "df['clean_sentence2'] = df['sentences2'].apply(clean_sentence)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Arquitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 236ms/step - accuracy: 0.3703 - loss: 0.6970 - val_accuracy: 0.6400 - val_loss: 0.6923\n",
      "Epoch 2/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.4528 - loss: 0.6933 - val_accuracy: 0.6600 - val_loss: 0.6911\n",
      "Epoch 3/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.5860 - loss: 0.6920 - val_accuracy: 0.6600 - val_loss: 0.6901\n",
      "Epoch 4/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.6205 - loss: 0.6907 - val_accuracy: 0.6600 - val_loss: 0.6890\n",
      "Epoch 5/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.5870 - loss: 0.6908 - val_accuracy: 0.6600 - val_loss: 0.6881\n",
      "Epoch 6/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.6166 - loss: 0.6893 - val_accuracy: 0.6600 - val_loss: 0.6871\n",
      "Epoch 7/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.6208 - loss: 0.6885 - val_accuracy: 0.6600 - val_loss: 0.6861\n",
      "Epoch 8/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.6091 - loss: 0.6883 - val_accuracy: 0.6600 - val_loss: 0.6851\n",
      "Epoch 9/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.6140 - loss: 0.6874 - val_accuracy: 0.6600 - val_loss: 0.6842\n",
      "Epoch 10/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.6100 - loss: 0.6870 - val_accuracy: 0.6600 - val_loss: 0.6833\n",
      "Epoch 11/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.6099 - loss: 0.6864 - val_accuracy: 0.6600 - val_loss: 0.6824\n",
      "Epoch 12/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.6123 - loss: 0.6857 - val_accuracy: 0.6600 - val_loss: 0.6816\n",
      "Epoch 13/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.6121 - loss: 0.6851 - val_accuracy: 0.6600 - val_loss: 0.6807\n",
      "Epoch 14/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.6324 - loss: 0.6829 - val_accuracy: 0.6600 - val_loss: 0.6799\n",
      "Epoch 15/15\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.5883 - loss: 0.6861 - val_accuracy: 0.6600 - val_loss: 0.6791\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7196 - loss: 0.6735\n",
      "Test Loss: 0.6734150648117065, Test Accuracy: 0.7200000286102295\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Lambda, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Combine all sentences to fit the tokenizer\n",
    "all_sentences = df['clean_sentence1'].tolist() + df['clean_sentence2'].tolist()\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_sentences)\n",
    "\n",
    "# Convert sentences to sequences\n",
    "sequences1 = tokenizer.texts_to_sequences(df['clean_sentence1'])\n",
    "sequences2 = tokenizer.texts_to_sequences(df['clean_sentence2'])\n",
    "\n",
    "# Pad the sequences\n",
    "max_length = max(len(seq) for seq in sequences1 + sequences2)\n",
    "padded_sequences1 = pad_sequences(sequences1, maxlen=max_length, padding='post')\n",
    "padded_sequences2 = pad_sequences(sequences2, maxlen=max_length, padding='post')\n",
    "\n",
    "# Convert labels to numpy array\n",
    "labels = np.array(df['is_similar'])\n",
    "\n",
    "# Split the data into training, validation, and testing sets (80-10-10 split)\n",
    "X_train1, X_temp1, y_train, y_temp = train_test_split(padded_sequences1, labels, test_size=0.2, random_state=42)\n",
    "X_train2, X_temp2 = train_test_split(padded_sequences2, test_size=0.2, random_state=42)\n",
    "\n",
    "X_val1, X_test1, y_val, y_test = train_test_split(X_temp1, y_temp, test_size=0.5, random_state=42)\n",
    "X_val2, X_test2 = train_test_split(X_temp2, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "def create_base_network(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128)(input)\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = LSTM(64)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "def create_bidirectional_base_network(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128)(input)\n",
    "    x = Bidirectional(LSTM(units=64, return_sequences=False))(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "# Create the Siamese network\n",
    "input_shape = (max_length, )\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# Compute the Euclidean distance between the two vectors\n",
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "# Compute the cosine distance between the two vectors\n",
    "def cosine_distance(vectors):\n",
    "    x, y = vectors\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return 1 - K.sum(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def l1_norm(vectors):\n",
    "    x, y = vectors\n",
    "    return 1 - K.abs(x - y)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([processed_a, processed_b])\n",
    "output = Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train1, X_train2], \n",
    "    y_train, \n",
    "    batch_size=50, \n",
    "    epochs=15, \n",
    "    validation_data=([X_val1, X_val2], y_val)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([X_test1, X_test2], y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
